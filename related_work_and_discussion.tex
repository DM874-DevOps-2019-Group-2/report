% 4 - Related Work and Discussion. In this section you review the relevant state of the art. This may include alternative solutions to the same challenge you have tried to address in your project, or alternative methodologies that you may have followed (e.g., choice of other technologies for implementing the project). Provide a discussion on the implications of your choices in the design of your work and the technologies/techniques that you have used.

\section{Related Work and Discussion}\label{sec:relatedWorkAndDiscussion}

% -- related work limited as the project was about using already well known technologies together

% -- kafka vs REST
The first intersting point of discussion is the choice of utilizing \textit{Apache Kafka} for inter-service communication, rather than the commonly used REST architechture. 
There are multiple reasons as to why we ended up using Kafka. 

Firstly, Kafka is very efficient, with the ability to saturate a 1GiB connection \cite{kafkaEfficiency}, even with small messages which are expected in a messaging/chat application.

Another positive aspect of using Kafka is the rather limited amount of boiler plate code required in each service to use the communication medium. Since REST runs on top of HTTP, using REST would require each service to run a webserver of its own, which, depending on the language, could be cumbersome.
On the other hand, while most modern languages have Kafka clients readily available, it is not all. As such, the programmer might be limited in choice of language.

The primary argument one could make for REST over Kafka, is the simplicity of providing API access to the individual services, however this can be mitigated by using an API Gateway which translates REST requests to Kafka messages and vice-versa, which is considered good practice for microservice systems either way.

% -- Jolie exec implemented in go pro/con
\bigskip

The use of Kafka eliminated \textit{Jolielang} as an option for implementing microservices in the system easily. However, as per verbal agreement, a user should be able to write Jolie code snippets to run on their messages.
Instead, the \texttt{Jolie-exec} service is implemented in \textit{golang}, which in many ways is quite similar to an extended version of \texttt{C}. 

As we decided to run the service on an ubuntu docker image, ubuntu group management is used along iptables to provide some level of security when running the user code snippets, and we are able to limit the runtime and memory usage of each snippet, something which seems unavailable in pure Jolie.

Since Jolie runs on the Java Virtual Machine, a rather large memory overhead is present for each snippet running, which brings us to the primary drawback of this approach.
Jolie would not run if the memory was limited to anything below 6 GiB, which is a ridiculous amount of memory for simple message processing.
It is possible that the could be avoided with some configuration, however, we did not find a nice solution.

% -- alternatives to jolie (resource cost wise)
\bigskip

If the application was to be used in production, the first obvious change would be discontinuation of Jolie snippets, migrating to a lower-overhead interpreted language such as \textit{Python} or \textit{Lua}.
If we assume a python runtime memory overhead of around 32MiB (testing this locally shows \textasciitilde 16MiB in python 2.7.17), we could fairly safely (assuming no file transfers through regular messages) limit the snippet's available memory to 32Mib, for a total of 64MiB per instance. 
With each user snippet instance being limited to 64MiB memory, \textasciitilde 96 times more user snippets could run simultaneously, greatly reducing infrastructure costs.
